# Model Card: Geograph Type Classifier v1.0

## Model Details
- **Developer:** Geograph Project Limited
- **Model Date:** January 2026
- **Model Type:** Multimodal Fusion (Linear Head)
- **Framework:** PyTorch 
- **Inspiration:** Directly inspired by the "ClipTheLandscape" project (Ilyankou et al., 2026).

## Intended Use
- **Primary Use:** Automated classification of Geograph Britain and Ireland images into their native "Type" categories.
- **Primary Audience:** Geospatial researchers, archivists, and developers working with the Geograph dataset.
- **Out of Scope:** This model is not designed for generic image classification. It requires specific spatial metadata (distance) and precomputed CLIP embeddings.

## Input Specification
The model requires two specific inputs:
1. **Visual Embedding:** A 512-dimensional float32 vector generated by the **CLIP ViT-B/32** image encoder.
2. **Spatial Metadata:** A quantized distance index (0â€“22) representing the Euclidean distance from the camera to the subject. (code provided to convert meters distance to index) 

## Output Specification (7 Target Classes)
The model outputs a 7-element tensor. Each element represents the probability of the following classes (ordered by index):
1. `Aerial` (0)
2. `Close Look` (1)
3. `Cross Far` (2)
4. `Extra` (3)
5. `Geograph` (4)
6. `Inside` (5)
7. `From Drone` (6)

*Note: This is a multi-label model. An image may simultaneously belong to multiple classes (e.g., Geograph + From Drone).*

## Training Data
- **Source:** [Geograph Britain and Ireland](https://www.geograph.org.uk/)
- **Size:** ~130,000 samples (Initial Release)
- **Features:** Precomputed CLIP vectors and metadata confidence weights.
- **Proxy Labels:** Images tagged as "From Above" (e.g., from bridges) are used as proxy training data for the "From Drone" class to mitigate data sparsity.

## Quantitative Analysis
- **Metric:** F1-Score (Macro Average)
- **Status:** The model is currently in a "Baseline" stage. Users should expect variance in accuracy for rare classes like `Inside` compared to high-frequency classes like `Geograph`.
- **Known Bias:** Performance may be higher for rural landscape shots than urban architecture due to the nature of the Geograph archive distribution.

## Ethical Considerations & Limitations
- **Data Privacy:** This model does not store or process raw image pixels, only mathematical embeddings.
- **Geographic Bias:** The model is specifically trained on the landscape and architecture of the British Isles and may not generalize to different geographical regions (e.g., tropical or desert landscapes).
- **Model Confidence:** The provided `weight` column in the dataset reflects the varying reliability of crowdsourced tags. The model inherits these uncertainties.

## Citation & Acknowledgments
If using this model, please cite the foundational methodology:
> Ilya Ilyankou, Natchapon Jongwiriyanurak, Tao Cheng, James Haworth,
> **CLIP the landscape: Automated tagging of crowdsourced landscape images**,
> *Remote Sensing Applications: Society and Environment*, 2026.

---
*Vibe Coded in collaboration with Gemini 3 (Flash).*
